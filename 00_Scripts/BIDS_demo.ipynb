{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhZ6hYOfgQSD"
   },
   "source": [
    "## Welcome to the Brainhack BIDS Demo!\n",
    "\n",
    "In this demo, we'll work with some example EEG source data. We're going to rename and re-organise the files into the BIDS format, and create some metadata files to describe our data. \n",
    "\n",
    "These data were collected to create a machine learning training dataset with the aim of continuously classifying which of two features was currently attended at each moment of each trial. We call the experiment “FeatAttnClass” for short. Below is a description of the task:\n",
    "\n",
    "*We set out to collect an EEG dataset to use to train various machine learning algorithms to detect the focus of feature-selective attention. Subjects were cued to attend to attend to either black or white moving dots, and respond to brief periods of coherent motion in the cued colour. The display consisted of either both black and white dots, or only the cued colour in randomly interleaved trials. The field of moving dots in the uncued colour never moved coherently, and should thus not have captured attention. The fields of dots flickered at 6 and 7.5 Hz. Colour and frequency were fully counterbalanced. Each trial consisted of a 1 second cue followed by 15 s of the dot motion stimulus.*\n",
    "\n",
    "The task instructions were as follows: \n",
    "\n",
    "*Participants were informed of the purpose of the study, and instructed to press the arrow keys corresponding to the direction of any epoch of coherent motion they saw in the cued colour.*\n",
    "\n",
    "The data were sampled at 1200 Hz using a g.tec amplifier (model g.USBamp) through the g.tec API running in MATLAB 2017a. Continuous data were recorded from five EEG channels (Iz, Oz, POz, O1, O2) arranged according to the international 10-20 system for electrode placement in a nylon head cap. The ground electrode was placed at Cz, and an ear reference was used. The powerline frequency was 50 Hz, and data were collected with a high pass filter at 1 Hz and a low pass filter at 100 Hz. The data is stored such that the EEG channels are in columns 1-5 in the matrix, and a trigger channel is at position 6. Changes in the amplitude of this trigger channel represent events. \n",
    "\n",
    "The data were recorded at the Queensland Brain Institute at The University of Queensland, which is located at: Building 79, The University of Queensland, St Lucia, Australia, 4072. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more resources on how to \"BIDS-ify\" your EEG data, we recommend checking out this paper:\n",
    "\n",
    "Pernet, C.R., Appelhoff, S., Gorgolewski, K.J. et al. EEG-BIDS, an extension to the brain imaging data structure for electroencephalography. Sci Data 6, 103 (2019). https://doi.org/10.1038/s41597-019-0104-8\n",
    "\n",
    "as well as these resources:\n",
    "https://github.com/bids-standard/bids-starter-kit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zozqeRlORhv8"
   },
   "source": [
    "### Step 1: Import libraries and set paths ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2hS70IWxbPp"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for file manipulation\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0p_c6HoxRQl_"
   },
   "outputs": [],
   "source": [
    "# Set paths for source data and BIDS data\n",
    "ROOTPATH = Path().cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTaxwbd6e1mh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get file names for relevant EEG and behavioural data \n",
    "eegFiles = sorted((ROOTPATH / '01_Sourcedata').glob('**/eeg*'))\n",
    "behFiles = sorted((ROOTPATH / '01_Sourcedata' ).glob('**/bhv*'))\n",
    "\n",
    "print('EEG Files found:', eegFiles)\n",
    "print('Behavioural Files found:', behFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the filenames for all of these files are the same for EEG data (eegData.mat) and behavioural data (bhvData.mat). Without the filepath, there is no way to know what subject, or even what experiment these data are for. This could easily lead to errors where we accidently analyse the same subject's data multiple times, or loose subject data. \n",
    "\n",
    "Further, the folder names vary, some contain unique initials, while others don't. Introducing this sort of variability makes it difficult to automate your analysis pipeline/file loading, and means each new person who uses the data needs to write unique code to load the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fR8M3I42hvYQ"
   },
   "source": [
    "### Step 2: Iterate through source data and save raw data in a proper folder structure and observing naming conventions ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the aformentioned issues, we'll copy our data into a new folder \"02_Rawdata\" where each subject has their own subfolder (\"Sub-01\", \"Sub-02\", etc). \n",
    "\n",
    "We will also rename the files to be BIDS compliant, with a name that features the subject ID, task name, and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the taskname:\n",
    "taskname = 'FeatAttnDec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on your operating system, you may need to switch between these splitters\n",
    "# splitter = '\\\\' # for Windows\n",
    "splitter = '/' # for MacOS and Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer source behavioural files to raw behavioural files\n",
    "for fpath in behFiles:\n",
    "    # get subject ID\n",
    "    pname = str(fpath.parent).split(splitter )[-1]    \n",
    "    subID = pname.replace('_', '\\t').replace('-', '\\t').split()[0][1:].rjust(2, '0')\n",
    "    \n",
    "    # Make Directory\n",
    "    (ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'beh').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Specify new file name\n",
    "    filename = 'sub-{}_task-'.format(subID) + taskname +  '_beh.mat'\n",
    "    rawfile = ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'beh'/ filename\n",
    "    \n",
    "    #Copy file\n",
    "    shutil.copyfile(fpath, rawfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer source EEG files to raw EEG files\n",
    "for fpath in eegFiles:\n",
    "    # get subject ID\n",
    "    pname = str(fpath.parent).split(splitter)[-1]\n",
    "    subID = pname.replace('_', '\\t').replace('-', '\\t').split()[0][1:].rjust(2, '0')\n",
    "    \n",
    "    # Make Directory\n",
    "    (ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'eeg').mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # Specify new file name\n",
    "    filename = 'sub-{}_task-'.format(subID) + taskname +  '_eeg.mat'\n",
    "    rawfile = ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'eeg'/ filename\n",
    "    \n",
    "    # Copy file\n",
    "    shutil.copyfile(fpath, rawfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that BIDS specifies specific file formats which are acceptable for EEG: \"The European Data Format (EDF), which is an ongoing international efort to provide a common data format for electrophysiological recordings that began in 19927, and the BrainVision Core Data Format, developed by Brain Products GmbH\"\n",
    "\n",
    "We won't cover data conversion in this script, but note that you would need to for your own data if it was not in an approved format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and store Channel metadata in tsv format ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject's EEG data needs to be stored with relevant metadata to help future researchers (including yourself!) to know the specifics of how the data were recorded\n",
    "\n",
    "We'll start with a tsv file, which outlines the parameters our EEG data storage variable. This will have the following collumns:\n",
    "- \"name\": The name of the electrode\n",
    "- \"type\": What sort of data is this?\n",
    "- \"units\": what units are the data in?\n",
    "- \"low cutoff\": If the data were filtered, what was the lowpass filter cutoff\n",
    "- \"high cutoff\": If the data were filtered, what was the highpass filter cutoff\n",
    "- \"reference\": What sort of reference was used?\n",
    "- \"group\" Was this electrode from a specific separate group?\n",
    "- \"sampling frequency\"\n",
    "- \"description\": do you want to give this variable a description?\n",
    "- \"notch\": Was there a notch filter, if so, what freq?\n",
    "- \"status\": Describe the status of the data, i.e. \"good\", \"bad\"\n",
    "- \"Status description\": describe what you mean by the status  i.e. very noisy in second half of exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tsv file\n",
    "\n",
    "# settings\n",
    "nchannels = 6\n",
    "ncolumns = 12\n",
    "\n",
    "# specify column names and create empty data vessel\n",
    "columnNames = [\"name\", \"type\", \"units\", \"low_cutoff\", \"high_cutoff\", \"reference\", \"group\", \"sampling_frequency\", \"description\", \"notch\", \"status\", \"Status_description\"]\n",
    "datempty = np.empty([nchannels,ncolumns]) # N rows x M cols\n",
    "\n",
    "# loop through subjects to create tsv for each dataset\n",
    "\n",
    "for fpath in eegFiles:\n",
    "    # get subject ID\n",
    "    pname = str(fpath.parent).split(splitter)[-1]\n",
    "    subID = pname.replace('_', '\\t').replace('-', '\\t').split()[0][1:].rjust(2, '0')\n",
    "    \n",
    "    # create Meta data structure\n",
    "    MetaData = pd.DataFrame(data = datempty,    columns = columnNames)\n",
    "\n",
    "    # Specify properties\n",
    "    MetaData.name = pd.DataFrame( [['Iz'], ['Oz'], ['POz'], ['O1'], ['O2'], ['TRIG']])\n",
    "    MetaData.type = pd.DataFrame( [['EEG'], ['EEG'], ['EEG'], ['EEG'], ['EEG'], ['TRIG']])\n",
    "    MetaData.units = 'μV'\n",
    "    MetaData.low_cutoff = 100\n",
    "    MetaData.high_cutoff = 1\n",
    "    MetaData.reference = pd.DataFrame( [['ear'], ['ear'], ['ear'], ['ear'], ['ear'], ['n/a']])\n",
    "    MetaData.group = 1;\n",
    "    MetaData.sampling_frequency = 1200\n",
    "    MetaData.description = 'n/a'\n",
    "    MetaData.notch = 50\n",
    "    \n",
    "    # specify specific channel status's for specific subjects if nescescarry\n",
    "    if subID == \"01\":\n",
    "        MetaData.status = pd.DataFrame( [['GOOD'], ['BAD'], ['GOOD'], ['GOOD'], ['GOOD'], ['GOOD']])\n",
    "        MetaData.Status_description = pd.DataFrame( [['n/a'], ['Channel exessively noisy through, suspect broken electrode'], ['n/a'], ['n/a'], ['n/a'], ['n/a']])\n",
    "    elif subID == \"02\":\n",
    "        MetaData.status = pd.DataFrame( [['OK'], ['OK'], ['OK'], ['OK'], ['OK'], ['OK']])\n",
    "        MetaData.Status_description = 'Regular artifact throughout, suspect electrical interference'\n",
    "    else:\n",
    "        MetaData.status = pd.DataFrame( [['GOOD'], ['GOOD'], ['GOOD'], ['GOOD'], ['GOOD'], ['GOOD']])\n",
    "        MetaData.Status_description = pd.DataFrame( [['n/a'], ['n/a'], ['n/a'], ['n/a'], ['n/a'], ['n/a']])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Specify file name\n",
    "    filename = 'sub-{}_task-'.format(subID) + taskname +  '_channels.tsv'\n",
    "    metadatafile = ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'eeg'/ filename\n",
    "    \n",
    "    # Write to tsv\n",
    "    MetaData.to_csv(\n",
    "        metadatafile, \n",
    "        sep = '\\t', na_rep = 'n/a', index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create and store task metadata in json format ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json file\n",
    "metadata = dict(\n",
    "    SubjectArtefactDescription = \"Strange Regular artifact - visually looks to be at about 0.5Hz, but resistant to filtering. Suspect this is some sort of electrical artifact in the room - testing was not perfomed in a farraday cage. Should not effect FFT based anayses\",\n",
    "    TaskName = taskname,\n",
    "    SamplingFrequency =   1200,    \n",
    "    PowerLineFrequency = 50,\n",
    "    SoftwareFilters = \"n/a\",\n",
    "    DCOffsetCorrection = \"n/a\",\n",
    "    EEGReference = \"ear\",\n",
    "    EEGGround = \"Cz\",\n",
    "    HardwareFilters = dict(\n",
    "        highpassfilter = dict(CutoffFrequency = 1),\n",
    "        lowpassfilter =  dict(CutoffFrequency = 100)\n",
    "    ),\n",
    "    Manufacturer = \"g.tec\",\n",
    "    ManufacturersModelName = \"g.USBamp\",\n",
    "    SoftwareVersions = \"g.tec API functions running in MATLAB 2017a\",\n",
    "    InstitutionName = \"Queensland Brain Institute, The University of Queensland\",\n",
    "    InstitutionAddress = \"Building 79, The University of Queensland, St Lucia, Australia, 4072\",\n",
    "    EEGChannelCount = \"5\",\n",
    "    TriggerChannelCount = \"1\",\n",
    "    RecordingDuration = \"2939.0933\",\n",
    "    RecordingType = \"continuous\",\n",
    "    TaskDescription = \"We set out to collect an EEG dataset to use to train various machine learning algorithms to detect the focus of feature-selective attention. Subjects were cued to attend to attend to either black or white moving dots, and respond to brief periods of coherent motion in the cued colour. The display consisted of either both black and white dots, or only the cued colour in randomly interleaved trials. The field of moving dots in the uncued colour never moved coherently, and should thus not have captured attention. The fields of dots flickered at 6 and 7.5 Hz. Colour and frequency were fully counterbalanced. Each trial consisted of a 1 second cue followed by 15 s of the dot motion stimulus. \",\n",
    "    Instructions = \"Participants were informed of the purpose of the study, and instructed to press the arrow keys corresponding to the direction of any epoch of coherent motion they saw in the cued colour.\"\n",
    ")\n",
    "\n",
    "# save json file\n",
    "for fpath in eegFiles:\n",
    "    # get subject ID\n",
    "    pname = str(fpath.parent).split(splitter)[-1]\n",
    "    subID = pname.replace('_', '\\t').replace('-', '\\t').split()[0][1:].rjust(2, '0')\n",
    "    \n",
    "    # generate file name\n",
    "    filename = 'sub-{}_task-'.format(subID) + taskname +  '_eeg.json'\n",
    "    metadatafile = ROOTPATH / '02_Rawdata' / 'sub-{}'.format(subID) / 'eeg'/ filename\n",
    "    \n",
    "    with metadatafile.open('w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Congratulations! ###\n",
    "\n",
    "Congrats! You now have the essential skills you'll need to organise your EEG data in the BIDS convention. \n",
    "1. You know how to rename and reorganise your files\n",
    "2. You know how to create a tsv file describing the channel metadata\n",
    "3. You know how to create a json file specifying the experiment metadata\n",
    "\n",
    "To completely follow the BIDS format, you still need a participants.tsv file, and a participants.json file specifying your participant metadata, as well as README.txt and CHANGES.txt files. If you have some spare time at the end of the session, you could go ahead and create these below!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of BIDS_demo.ipynb",
   "provenance": [
    {
     "file_id": "19s1qRHusLm7RE0MaZygPIhA2LN9PFp0J",
     "timestamp": 1592201227762
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}